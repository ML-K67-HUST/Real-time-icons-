{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3909f64cb512446c95ebe24cf5b3041b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6ef73110b134a029a9da940196ec66a",
              "IPY_MODEL_335f1f97a20f4ef3b08b9a1e1e0d21a3"
            ],
            "layout": "IPY_MODEL_88b3c23974f2453fa8fed21bbb576232"
          }
        },
        "b6ef73110b134a029a9da940196ec66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c68247b63a6c4e5a8456389b8163021d",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab639182b254085ad910446cb80eebb",
            "value": "0.033 MB of 0.033 MB uploaded\r"
          }
        },
        "335f1f97a20f4ef3b08b9a1e1e0d21a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc45e95a16e48faa5c635e04a26dcd0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7ac7931e76945ddbd216e1bec5fab3d",
            "value": 1
          }
        },
        "88b3c23974f2453fa8fed21bbb576232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68247b63a6c4e5a8456389b8163021d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab639182b254085ad910446cb80eebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc45e95a16e48faa5c635e04a26dcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ac7931e76945ddbd216e1bec5fab3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### INSTALLATION"
      ],
      "metadata": {
        "id": "_PKVdnYWPHWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install scikit-multilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPARitKRIeRq",
        "outputId": "e3b12c25-0351-4cf1-c2a7-3c7d4536677c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d glove.6B/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_BQ6RmJusMt",
        "outputId": "c76a428a-a18d-4e05-cf20-1328efd78eb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-14 15:46:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-12-14 15:46:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 43s  \n",
            "\n",
            "2024-12-14 15:49:10 (5.04 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B/glove.6B.50d.txt  \n",
            "  inflating: glove.6B/glove.6B.100d.txt  \n",
            "  inflating: glove.6B/glove.6B.200d.txt  \n",
            "  inflating: glove.6B/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "EWAmwoVtPQct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d2swvHC-lnlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58915721-4280-4749-e9a7-f2a66581103d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import reuters\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk import WordNetLemmatizer\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "\n",
        "from sklearn.metrics import hamming_loss, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import re\n",
        "import sys\n",
        "import warnings\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "from typing import Tuple, List\n",
        "from functools import partial\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AdamW\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "lM89KGJRPVEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = nltk.corpus.reuters.fileids()\n",
        "labels = [nltk.corpus.reuters.categories(doc) for doc in docs]\n",
        "texts = [nltk.corpus.reuters.raw(doc) for doc in docs]\n",
        "mlb = MultiLabelBinarizer()\n",
        "bin_labels = mlb.fit_transform(labels)\n",
        "label_names = mlb.classes_"
      ],
      "metadata": {
        "id": "cWu2tPrTtCUU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'text': texts})\n",
        "for i, label in enumerate(label_names):\n",
        "    df[label] = bin_labels[:, i]\n",
        "\n",
        "print(df.head())\n",
        "labels = df.columns[1:]"
      ],
      "metadata": {
        "id": "aslo0xrAtluf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c3ff92-79bd-49d4-95bc-6a002ebb992a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  acq  alum  barley  bop  \\\n",
            "0  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...    0     0       0    0   \n",
            "1  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...    0     0       0    0   \n",
            "2  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...    0     0       0    0   \n",
            "3  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...    0     0       0    0   \n",
            "4  INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...    0     0       0    0   \n",
            "\n",
            "   carcass  castor-oil  cocoa  coconut  coconut-oil  ...  sun-oil  sunseed  \\\n",
            "0        0           0      0        0            0  ...        0        0   \n",
            "1        0           0      0        0            0  ...        0        0   \n",
            "2        0           0      0        0            0  ...        0        0   \n",
            "3        0           0      0        0            0  ...        0        0   \n",
            "4        0           0      0        0            0  ...        0        0   \n",
            "\n",
            "   tea  tin  trade  veg-oil  wheat  wpi  yen  zinc  \n",
            "0    0    0      1        0      0    0    0     0  \n",
            "1    0    0      0        0      0    0    0     0  \n",
            "2    0    0      0        0      0    0    0     0  \n",
            "3    0    1      1        0      0    0    0     0  \n",
            "4    0    0      0        1      0    0    0     0  \n",
            "\n",
            "[5 rows x 91 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
        "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanHtml(sentence):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "def keepAlpha(sentence):\n",
        "    alpha_sent = \"\"\n",
        "    for word in sentence.split():\n",
        "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
        "        alpha_sent += alpha_word\n",
        "        alpha_sent += \" \"\n",
        "    alpha_sent = alpha_sent.strip()\n",
        "    return alpha_sent\n",
        "\n",
        "def removeStopWords(sentence):\n",
        "    global re_stop_words\n",
        "    return re_stop_words.sub(\" \", sentence)\n",
        "\n",
        "def lemmatize(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemSentence = \"\"\n",
        "    for word in sentence.split():\n",
        "        lem = lemmatizer.lemmatize(word)\n",
        "        lemSentence += lem\n",
        "        lemSentence += \" \"\n",
        "    lemSentence = lemSentence.strip()\n",
        "    return lemSentence\n",
        "\n",
        "def preprocess_text(train_df):\n",
        "    train_df['text'] = train_df['text'].str.lower()\n",
        "    train_df['text'] = train_df['text'].apply(cleanHtml)\n",
        "    train_df['text'] = train_df['text'].apply(cleanPunc)\n",
        "    train_df['text'] = train_df['text'].apply(keepAlpha)\n",
        "    train_df['text'] = train_df['text'].apply(removeStopWords)\n",
        "    train_df['text'] = train_df['text'].apply(lemmatize)\n",
        "    return train_df\n",
        "\n",
        "def create_glove_embedding_matrix(tokenizer, glove_file_path):\n",
        "    glove_embeddings = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.split()\n",
        "            word = parts[0]\n",
        "            vector = np.array(parts[1:], dtype=np.float32)\n",
        "            glove_embeddings[word] = vector\n",
        "\n",
        "    vocab_size = len(tokenizer.index_word) + 1\n",
        "    #File 300 dim expected\n",
        "    embedding_dim = 300\n",
        "    glove_embedding_matrix = torch.zeros(vocab_size, embedding_dim)\n",
        "\n",
        "    unknown_words = 0\n",
        "    for i in range(1, vocab_size):\n",
        "        word = tokenizer.index_word[i]\n",
        "        if word in glove_embeddings.keys():\n",
        "            glove_embedding_matrix[i] = torch.from_numpy(glove_embeddings[word]).float()\n",
        "        else:\n",
        "            unknown_words += 1\n",
        "\n",
        "    print(\"GloVe embedding matrix created!\")\n",
        "    print('Vocabulary size: {}'.format(vocab_size))\n",
        "    print('Total unknown words: {}'.format(unknown_words))\n",
        "\n",
        "    return glove_embeddings, glove_embedding_matrix\n",
        "\n",
        "def create_glove_label_embedding(labels, glove_embeddings):\n",
        "    glove_label_embedding = torch.zeros(len(labels), 300)\n",
        "\n",
        "    for index, label in enumerate(labels):\n",
        "        wrds = label.split('_')\n",
        "        for l in wrds:\n",
        "            if l in glove_embeddings.keys():\n",
        "                glove_label_embedding[index] += torch.from_numpy(glove_embeddings[l])\n",
        "        glove_label_embedding[index] /= len(wrds)\n",
        "\n",
        "    return glove_label_embedding\n",
        "\n",
        "\n",
        "#Build adjacency matrix based on Co-Occurencies label\n",
        "def create_adjacency_matrix_cooccurance(data_label):\n",
        "  cooccur_matrix = np.zeros((data_label.shape[1], data_label.shape[1]), dtype=float)\n",
        "  for y in data_label:\n",
        "      y = list(y)\n",
        "      for i in range(len(y)):\n",
        "          for j in range(len(y)):\n",
        "            #data_label\n",
        "              if y[i] == 1 and y[j] == 1:\n",
        "                  cooccur_matrix[i, j] += 1\n",
        "  row_sums = data_label.sum(axis=0)\n",
        "\n",
        "  for i in range(cooccur_matrix.shape[0]):\n",
        "    for j in range(cooccur_matrix.shape[0]):\n",
        "      if row_sums[i]!=0:\n",
        "        cooccur_matrix[i][j]=cooccur_matrix[i,j]/row_sums[i]\n",
        "      else:\n",
        "        cooccur_matrix[i][j]=cooccur_matrix[i,j]\n",
        "\n",
        "  return cooccur_matrix\n",
        "\n",
        "class dataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x  = x\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "dJCdz5uxmMGz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = preprocess_text(df)"
      ],
      "metadata": {
        "id": "v_wY_jw_t3rI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text'].values\n",
        "y = df.iloc[:,1:].values\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=200)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape )"
      ],
      "metadata": {
        "id": "a-0730hDzUu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54bce20-ec1a-4b7a-db36-f14cb48f2167"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10788,) (10788, 90)\n",
            "(8630,) (2158,) (8630, 90) (2158, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL"
      ],
      "metadata": {
        "id": "OOqCnS1uP4Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAGNET(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, adjacency, embeddings, heads=4, slope=0.01, dropout=0.5):\n",
        "    super(MAGNET, self).__init__()\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings)\n",
        "    self.biLSTM = nn.LSTM(input_size,hidden_size,batch_first=True,bidirectional=True)\n",
        "    self.adjacency = nn.Parameter(adjacency)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.edge_weights = nn.Linear(hidden_size*2*2, 1, bias=False)\n",
        "    self.activation = nn.LeakyReLU(slope)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.heads = heads\n",
        "    self.transform_dim1 = nn.Linear(input_size, hidden_size*2, bias=False)\n",
        "    self.transform_dim2 = nn.Linear(hidden_size*2, hidden_size*2, bias=False)\n",
        "    self.transform_dimensions = [self.transform_dim1, self.transform_dim2]\n",
        "\n",
        "  def forward(self, token, label_embedding):\n",
        "      #BILSTM part\n",
        "      features = self.embedding(token)\n",
        "      out, (h, _) = self.biLSTM(features)\n",
        "      embedding = torch.cat([h[-2, :, :], h[-1, :, :]], dim=1)\n",
        "      embedding = self.dropout(embedding)\n",
        "\n",
        "      #GAT PART\n",
        "      for td in self.transform_dimensions: #Two Multiheaded GAT layers\n",
        "        outputs = []\n",
        "        for head in range(self.heads):\n",
        "          label_embed = td(label_embedding)\n",
        "          n, embed_size = label_embed.shape\n",
        "\n",
        "          label_embed_combinations = label_embed.unsqueeze(1).expand(-1, n, -1)\n",
        "          label_embed_combinations = torch.cat([label_embed_combinations, label_embed.unsqueeze(0).expand(n, -1, -1)], dim=2)\n",
        "          e = self.activation(self.edge_weights(label_embed_combinations).squeeze(2))\n",
        "\n",
        "          attention_coefficients = self.tanh(torch.mul(e,self.adjacency))\n",
        "\n",
        "          new_h = torch.matmul(attention_coefficients.to(label_embed.dtype), label_embed)\n",
        "          outputs.append(new_h)\n",
        "        outputs = self.activation(torch.mean(torch.stack(outputs, dim=0),dim=0))\n",
        "\n",
        "        label_embedding = outputs\n",
        "      attention_features = self.dropout(label_embedding)\n",
        "      attention_features = attention_features.transpose(0, 1)\n",
        "      predicted_labels = torch.matmul(embedding, attention_features)\n",
        "      return predicted_labels"
      ],
      "metadata": {
        "id": "wLihiGRwxOmR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, loss, ckpt_path):\n",
        "    \"\"\"\n",
        "    Save the best model checkpoint\n",
        "    \"\"\"\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(state, ckpt_path)\n",
        "    print(f\"Saved best model to {ckpt_path}\")\n",
        "\n",
        "def load_checkpoint(model, ckpt_path):\n",
        "    \"\"\"\n",
        "    Load the best model checkpoint\n",
        "    \"\"\"\n",
        "    if not os.path.exists(ckpt_path):\n",
        "        print(\"No checkpoint found\")\n",
        "        return model\n",
        "\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']} with loss {checkpoint['loss']:.5f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "QCQrqIQ1dwxJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = 'MAGNET_best_model_final.pt'"
      ],
      "metadata": {
        "id": "xHk-XCpb0Ups"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, label_embedding, y_train,\n",
        "          total_epoch=250, batch_size=250, learning_rate=0.001,\n",
        "          ckpt_path=ckpt_path):\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"magnet-classification\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"epochs\": total_epoch,\n",
        "            \"architecture\": \"MAGNET\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    label_embedding = label_embedding.to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_data = DataLoader(dataset(X_train, y_train), batch_size=batch_size)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, total_epoch + 1):\n",
        "        running_loss = 0\n",
        "        y_pred = []\n",
        "        model.train()\n",
        "\n",
        "        for index, (X, y) in enumerate(train_data):\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X.to(device), label_embedding)\n",
        "            loss = criterion(out, y.to(device).float())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
        "            optimizer.step()\n",
        "            y_pred.append(torch.sigmoid(out.detach()).round().cpu())\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        y_pred = torch.vstack(y_pred)\n",
        "        f1score = f1_score(y_train, y_pred, average='micro')\n",
        "        hammingloss = hamming_loss(y_train, y_pred)\n",
        "\n",
        "        # Save best model\n",
        "        if running_loss < best_loss:\n",
        "            best_loss = running_loss\n",
        "            save_checkpoint(model, optimizer, epoch, running_loss, ckpt_path)\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": running_loss,\n",
        "            \"hamming_loss\": hammingloss,\n",
        "            \"micro_f1_score\": f1score\n",
        "        })\n",
        "\n",
        "        print(f'epoch:{epoch} loss:{running_loss:.5f} hamming_loss:{hammingloss:.5f} micro_f1score:{f1score:.5f}')\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "9x5UWvoOxyWd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING"
      ],
      "metadata": {
        "id": "zXTh-YGNP_qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=20000,oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences_text_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_text_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(pad_sequences(sequences_text_train, maxlen=70))\n",
        "X_test = torch.from_numpy(pad_sequences(sequences_text_test, maxlen=70))\n",
        "\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape )\n",
        "print(len(tokenizer.index_word))"
      ],
      "metadata": {
        "id": "_zdQS46uBajw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a50a40-bd7e-4044-b5d9-22d5361e0fa0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8630, 70]) torch.Size([2158, 70]) torch.Size([8630, 90]) torch.Size([2158, 90])\n",
            "24629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load glove embedding\n",
        "glove_embeddings = {}\n",
        "with open('glove.6B/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        vector = np.array(parts[1:], dtype=np.float32)\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.index_word)+1\n",
        "glove_embedding_matrix = torch.zeros(VOCAB_SIZE, 300)\n",
        "\n",
        "unk = 0\n",
        "for i in range(1, VOCAB_SIZE):\n",
        "  word = tokenizer.index_word[i]\n",
        "  if word in glove_embeddings.keys():\n",
        "    glove_embedding_matrix[i] = torch.from_numpy(glove_embeddings[word]).float()\n",
        "  else:\n",
        "    unk +=1\n",
        "print('VOCAB_SIZE : {}'.format(VOCAB_SIZE))\n",
        "print('TOTAL OF UNKNOWN WORD : {}'.format(unk))"
      ],
      "metadata": {
        "id": "wIDBs1828WSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b739358-de76-4a68-c50a-a7f5db965052"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB_SIZE : 24630\n",
            "TOTAL OF UNKNOWN WORD : 4664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_matrix = create_adjacency_matrix_cooccurance(y_train.numpy())\n",
        "adj_matrix = torch.tensor(adj_matrix)\n",
        "adj_matrix"
      ],
      "metadata": {
        "id": "QXFcb54YzEce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89ea85a-9377-4931-a92c-5a6500e9e701"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 5.2910e-04, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         1.0582e-03],\n",
              "        [2.2222e-02, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         2.2222e-02],\n",
              "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        ...,\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 1.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [7.4074e-02, 3.7037e-02, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         1.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_label_embedding = torch.zeros(len(labels),300)\n",
        "\n",
        "for index, label in enumerate(labels):\n",
        "  wrds = label.split('-')\n",
        "  for l in wrds:\n",
        "    if l in glove_embeddings.keys():\n",
        "        glove_label_embedding[index] +=  torch.from_numpy(glove_embeddings[l])\n",
        "  glove_label_embedding[index]=glove_label_embedding[index]/len(wrds)\n",
        "\n",
        "print(glove_label_embedding)"
      ],
      "metadata": {
        "id": "AOlVUO8sy5V8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd487853-0708-47e5-be1e-d47c1b05abbb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1796, -0.1051, -0.5564,  ..., -0.0633,  0.3732, -0.2873],\n",
            "        [ 0.1101,  0.4061,  0.2036,  ..., -0.1957, -0.4627,  0.6931],\n",
            "        [-0.3568, -0.1348,  0.0790,  ..., -0.0384,  0.2948,  0.1996],\n",
            "        ...,\n",
            "        [-0.1446,  0.0594, -0.1450,  ..., -0.0334,  0.1966,  0.4136],\n",
            "        [-0.5990, -0.3234, -0.2749,  ...,  0.6343,  0.5300,  0.0299],\n",
            "        [-0.4541, -0.1300, -0.5178,  ..., -1.1637, -0.2056, -0.3177]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MAGNET(300, 250, adj_matrix, glove_embedding_matrix,heads=8)\n",
        "train(model, X_train, glove_label_embedding,y_train,total_epoch=250, ckpt_path=ckpt_path)"
      ],
      "metadata": {
        "id": "raUsUOqgzBIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3909f64cb512446c95ebe24cf5b3041b",
            "b6ef73110b134a029a9da940196ec66a",
            "335f1f97a20f4ef3b08b9a1e1e0d21a3",
            "88b3c23974f2453fa8fed21bbb576232",
            "c68247b63a6c4e5a8456389b8163021d",
            "2ab639182b254085ad910446cb80eebb",
            "ecc45e95a16e48faa5c635e04a26dcd0",
            "c7ac7931e76945ddbd216e1bec5fab3d"
          ]
        },
        "outputId": "aadab619-5bbe-4c5b-bd59-75bb08ddd54a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241214_160032-ze0gqgn4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification/runs/ze0gqgn4' target=\"_blank\">resilient-firefly-13</a></strong> to <a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification' target=\"_blank\">https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification/runs/ze0gqgn4' target=\"_blank\">https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification/runs/ze0gqgn4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:1 loss:6.39439 hamming_loss:0.03530 micro_f1score:0.01735\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:2 loss:1.82392 hamming_loss:0.01399 micro_f1score:0.00220\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:3 loss:1.63280 hamming_loss:0.01379 micro_f1score:0.00112\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:4 loss:1.52110 hamming_loss:0.01376 micro_f1score:0.00688\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:5 loss:1.36316 hamming_loss:0.01184 micro_f1score:0.31944\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:6 loss:1.22197 hamming_loss:0.00993 micro_f1score:0.48730\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:7 loss:1.10257 hamming_loss:0.00893 micro_f1score:0.56201\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:8 loss:0.98730 hamming_loss:0.00810 micro_f1score:0.61267\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:9 loss:0.92494 hamming_loss:0.00779 micro_f1score:0.63827\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:10 loss:0.86902 hamming_loss:0.00746 micro_f1score:0.66113\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:11 loss:0.84016 hamming_loss:0.00729 micro_f1score:0.67043\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:12 loss:0.78854 hamming_loss:0.00701 micro_f1score:0.69001\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:13 loss:0.75486 hamming_loss:0.00680 micro_f1score:0.70109\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:14 loss:0.72003 hamming_loss:0.00655 micro_f1score:0.71571\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:15 loss:0.68578 hamming_loss:0.00634 micro_f1score:0.72893\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:16 loss:0.66078 hamming_loss:0.00615 micro_f1score:0.73940\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:17 loss:0.64098 hamming_loss:0.00592 micro_f1score:0.75136\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:18 loss:0.62044 hamming_loss:0.00580 micro_f1score:0.75822\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:19 loss:0.60952 hamming_loss:0.00573 micro_f1score:0.76077\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:20 loss:0.59667 hamming_loss:0.00565 micro_f1score:0.76583\n",
            "epoch:21 loss:0.60502 hamming_loss:0.00573 micro_f1score:0.76210\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:22 loss:0.55842 hamming_loss:0.00534 micro_f1score:0.78075\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:23 loss:0.54635 hamming_loss:0.00530 micro_f1score:0.78365\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:24 loss:0.52792 hamming_loss:0.00521 micro_f1score:0.78748\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:25 loss:0.52488 hamming_loss:0.00517 micro_f1score:0.79070\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:26 loss:0.50342 hamming_loss:0.00507 micro_f1score:0.79479\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:27 loss:0.48930 hamming_loss:0.00488 micro_f1score:0.80371\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:28 loss:0.47245 hamming_loss:0.00478 micro_f1score:0.80859\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:29 loss:0.46849 hamming_loss:0.00473 micro_f1score:0.81110\n",
            "epoch:30 loss:0.47110 hamming_loss:0.00479 micro_f1score:0.80843\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:31 loss:0.43943 hamming_loss:0.00457 micro_f1score:0.81813\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:32 loss:0.41503 hamming_loss:0.00439 micro_f1score:0.82663\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:33 loss:0.39467 hamming_loss:0.00416 micro_f1score:0.83673\n",
            "epoch:34 loss:0.39686 hamming_loss:0.00417 micro_f1score:0.83631\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:35 loss:0.38949 hamming_loss:0.00409 micro_f1score:0.83968\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:36 loss:0.36646 hamming_loss:0.00389 micro_f1score:0.84862\n",
            "epoch:37 loss:0.37363 hamming_loss:0.00405 micro_f1score:0.84266\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:38 loss:0.36179 hamming_loss:0.00384 micro_f1score:0.85118\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:39 loss:0.34310 hamming_loss:0.00373 micro_f1score:0.85578\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:40 loss:0.33781 hamming_loss:0.00362 micro_f1score:0.86047\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:41 loss:0.33776 hamming_loss:0.00369 micro_f1score:0.85871\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:42 loss:0.32538 hamming_loss:0.00350 micro_f1score:0.86538\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:43 loss:0.31969 hamming_loss:0.00340 micro_f1score:0.87073\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:44 loss:0.30758 hamming_loss:0.00330 micro_f1score:0.87371\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:45 loss:0.29467 hamming_loss:0.00326 micro_f1score:0.87600\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:46 loss:0.29085 hamming_loss:0.00313 micro_f1score:0.88166\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:47 loss:0.28346 hamming_loss:0.00305 micro_f1score:0.88470\n",
            "epoch:48 loss:0.28872 hamming_loss:0.00317 micro_f1score:0.88045\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:49 loss:0.27928 hamming_loss:0.00304 micro_f1score:0.88539\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:50 loss:0.27649 hamming_loss:0.00301 micro_f1score:0.88617\n",
            "epoch:51 loss:0.30184 hamming_loss:0.00315 micro_f1score:0.88064\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:52 loss:0.26545 hamming_loss:0.00287 micro_f1score:0.89234\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:53 loss:0.26009 hamming_loss:0.00285 micro_f1score:0.89302\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:54 loss:0.24695 hamming_loss:0.00270 micro_f1score:0.89905\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:55 loss:0.24488 hamming_loss:0.00264 micro_f1score:0.90146\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:56 loss:0.24107 hamming_loss:0.00262 micro_f1score:0.90231\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:57 loss:0.24054 hamming_loss:0.00258 micro_f1score:0.90401\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:58 loss:0.22724 hamming_loss:0.00251 micro_f1score:0.90645\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:59 loss:0.22423 hamming_loss:0.00248 micro_f1score:0.90802\n",
            "epoch:60 loss:0.22500 hamming_loss:0.00248 micro_f1score:0.90815\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:61 loss:0.22377 hamming_loss:0.00241 micro_f1score:0.91024\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:62 loss:0.21824 hamming_loss:0.00239 micro_f1score:0.91139\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:63 loss:0.20100 hamming_loss:0.00220 micro_f1score:0.91848\n",
            "epoch:64 loss:0.20264 hamming_loss:0.00221 micro_f1score:0.91834\n",
            "epoch:65 loss:0.20216 hamming_loss:0.00222 micro_f1score:0.91795\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:66 loss:0.19011 hamming_loss:0.00206 micro_f1score:0.92397\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:67 loss:0.18564 hamming_loss:0.00204 micro_f1score:0.92469\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:68 loss:0.17878 hamming_loss:0.00197 micro_f1score:0.92714\n",
            "epoch:69 loss:0.18186 hamming_loss:0.00197 micro_f1score:0.92738\n",
            "epoch:70 loss:0.17923 hamming_loss:0.00194 micro_f1score:0.92869\n",
            "epoch:71 loss:0.19832 hamming_loss:0.00210 micro_f1score:0.92231\n",
            "epoch:72 loss:0.18783 hamming_loss:0.00202 micro_f1score:0.92563\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:73 loss:0.17244 hamming_loss:0.00187 micro_f1score:0.93100\n",
            "epoch:74 loss:0.18135 hamming_loss:0.00190 micro_f1score:0.93025\n",
            "epoch:75 loss:0.18215 hamming_loss:0.00192 micro_f1score:0.92939\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:76 loss:0.15945 hamming_loss:0.00176 micro_f1score:0.93550\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:77 loss:0.15877 hamming_loss:0.00174 micro_f1score:0.93621\n",
            "epoch:78 loss:0.15896 hamming_loss:0.00171 micro_f1score:0.93724\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:79 loss:0.15779 hamming_loss:0.00165 micro_f1score:0.93916\n",
            "epoch:80 loss:0.15917 hamming_loss:0.00177 micro_f1score:0.93536\n",
            "epoch:81 loss:0.16242 hamming_loss:0.00178 micro_f1score:0.93481\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:82 loss:0.14893 hamming_loss:0.00159 micro_f1score:0.94154\n",
            "epoch:83 loss:0.15484 hamming_loss:0.00167 micro_f1score:0.93886\n",
            "epoch:84 loss:0.15150 hamming_loss:0.00164 micro_f1score:0.94001\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:85 loss:0.14809 hamming_loss:0.00158 micro_f1score:0.94198\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:86 loss:0.14567 hamming_loss:0.00156 micro_f1score:0.94286\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:87 loss:0.14031 hamming_loss:0.00153 micro_f1score:0.94409\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:88 loss:0.13453 hamming_loss:0.00149 micro_f1score:0.94546\n",
            "epoch:89 loss:0.13481 hamming_loss:0.00147 micro_f1score:0.94640\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:90 loss:0.13133 hamming_loss:0.00144 micro_f1score:0.94746\n",
            "epoch:91 loss:0.13200 hamming_loss:0.00140 micro_f1score:0.94898\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:92 loss:0.12847 hamming_loss:0.00141 micro_f1score:0.94862\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:93 loss:0.12415 hamming_loss:0.00135 micro_f1score:0.95074\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:94 loss:0.11933 hamming_loss:0.00131 micro_f1score:0.95231\n",
            "epoch:95 loss:0.12101 hamming_loss:0.00133 micro_f1score:0.95160\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:96 loss:0.11586 hamming_loss:0.00128 micro_f1score:0.95337\n",
            "epoch:97 loss:0.12374 hamming_loss:0.00140 micro_f1score:0.94898\n",
            "epoch:98 loss:0.11618 hamming_loss:0.00127 micro_f1score:0.95354\n",
            "epoch:99 loss:0.11839 hamming_loss:0.00126 micro_f1score:0.95423\n",
            "epoch:100 loss:0.12591 hamming_loss:0.00139 micro_f1score:0.94929\n",
            "epoch:101 loss:0.12322 hamming_loss:0.00131 micro_f1score:0.95220\n",
            "epoch:102 loss:0.12678 hamming_loss:0.00136 micro_f1score:0.95027\n",
            "epoch:103 loss:0.12313 hamming_loss:0.00133 micro_f1score:0.95172\n",
            "epoch:104 loss:0.11658 hamming_loss:0.00126 micro_f1score:0.95390\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:105 loss:0.10717 hamming_loss:0.00118 micro_f1score:0.95695\n",
            "epoch:106 loss:0.11387 hamming_loss:0.00126 micro_f1score:0.95412\n",
            "epoch:107 loss:0.11183 hamming_loss:0.00119 micro_f1score:0.95638\n",
            "epoch:108 loss:0.11046 hamming_loss:0.00116 micro_f1score:0.95778\n",
            "epoch:109 loss:0.11892 hamming_loss:0.00123 micro_f1score:0.95513\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:110 loss:0.10432 hamming_loss:0.00112 micro_f1score:0.95924\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:111 loss:0.09946 hamming_loss:0.00105 micro_f1score:0.96186\n",
            "epoch:112 loss:0.10028 hamming_loss:0.00106 micro_f1score:0.96129\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:113 loss:0.09855 hamming_loss:0.00105 micro_f1score:0.96186\n",
            "epoch:114 loss:0.09992 hamming_loss:0.00109 micro_f1score:0.96022\n",
            "epoch:115 loss:0.10072 hamming_loss:0.00110 micro_f1score:0.95997\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:116 loss:0.09581 hamming_loss:0.00105 micro_f1score:0.96165\n",
            "epoch:117 loss:0.09765 hamming_loss:0.00102 micro_f1score:0.96291\n",
            "epoch:118 loss:0.09732 hamming_loss:0.00101 micro_f1score:0.96310\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:119 loss:0.08886 hamming_loss:0.00098 micro_f1score:0.96444\n",
            "epoch:120 loss:0.09140 hamming_loss:0.00100 micro_f1score:0.96382\n",
            "epoch:121 loss:0.09323 hamming_loss:0.00098 micro_f1score:0.96423\n",
            "epoch:122 loss:0.09051 hamming_loss:0.00098 micro_f1score:0.96436\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:123 loss:0.08736 hamming_loss:0.00094 micro_f1score:0.96573\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:124 loss:0.08579 hamming_loss:0.00091 micro_f1score:0.96698\n",
            "epoch:125 loss:0.09755 hamming_loss:0.00100 micro_f1score:0.96382\n",
            "epoch:126 loss:0.08868 hamming_loss:0.00096 micro_f1score:0.96516\n",
            "epoch:127 loss:0.09003 hamming_loss:0.00094 micro_f1score:0.96591\n",
            "epoch:128 loss:0.09222 hamming_loss:0.00097 micro_f1score:0.96477\n",
            "epoch:129 loss:0.09924 hamming_loss:0.00103 micro_f1score:0.96253\n",
            "epoch:130 loss:0.09123 hamming_loss:0.00095 micro_f1score:0.96555\n",
            "epoch:131 loss:0.08661 hamming_loss:0.00090 micro_f1score:0.96719\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:132 loss:0.08321 hamming_loss:0.00089 micro_f1score:0.96743\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:133 loss:0.08311 hamming_loss:0.00087 micro_f1score:0.96851\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:134 loss:0.08068 hamming_loss:0.00088 micro_f1score:0.96812\n",
            "epoch:135 loss:0.08157 hamming_loss:0.00083 micro_f1score:0.96984\n",
            "epoch:136 loss:0.08146 hamming_loss:0.00084 micro_f1score:0.96951\n",
            "epoch:137 loss:0.09093 hamming_loss:0.00095 micro_f1score:0.96538\n",
            "epoch:138 loss:0.16367 hamming_loss:0.00156 micro_f1score:0.94299\n",
            "epoch:139 loss:0.13209 hamming_loss:0.00136 micro_f1score:0.95048\n",
            "epoch:140 loss:0.10202 hamming_loss:0.00107 micro_f1score:0.96118\n",
            "epoch:141 loss:0.10127 hamming_loss:0.00105 micro_f1score:0.96188\n",
            "epoch:142 loss:0.11642 hamming_loss:0.00117 micro_f1score:0.95762\n",
            "epoch:143 loss:0.12982 hamming_loss:0.00128 micro_f1score:0.95317\n",
            "epoch:144 loss:0.10037 hamming_loss:0.00105 micro_f1score:0.96168\n",
            "epoch:145 loss:0.08638 hamming_loss:0.00092 micro_f1score:0.96640\n",
            "epoch:146 loss:0.08234 hamming_loss:0.00086 micro_f1score:0.96883\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:147 loss:0.07703 hamming_loss:0.00079 micro_f1score:0.97137\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:148 loss:0.07506 hamming_loss:0.00080 micro_f1score:0.97095\n",
            "epoch:149 loss:0.07756 hamming_loss:0.00085 micro_f1score:0.96927\n",
            "epoch:150 loss:0.07936 hamming_loss:0.00085 micro_f1score:0.96919\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:151 loss:0.07411 hamming_loss:0.00079 micro_f1score:0.97120\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:152 loss:0.07084 hamming_loss:0.00077 micro_f1score:0.97206\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:153 loss:0.06865 hamming_loss:0.00072 micro_f1score:0.97387\n",
            "epoch:154 loss:0.07315 hamming_loss:0.00076 micro_f1score:0.97251\n",
            "epoch:155 loss:0.07161 hamming_loss:0.00075 micro_f1score:0.97284\n",
            "epoch:156 loss:0.07430 hamming_loss:0.00078 micro_f1score:0.97156\n",
            "epoch:157 loss:0.07369 hamming_loss:0.00073 micro_f1score:0.97341\n",
            "epoch:158 loss:0.06945 hamming_loss:0.00072 micro_f1score:0.97392\n",
            "epoch:159 loss:0.06886 hamming_loss:0.00070 micro_f1score:0.97449\n",
            "epoch:160 loss:0.08269 hamming_loss:0.00088 micro_f1score:0.96818\n",
            "epoch:161 loss:0.08102 hamming_loss:0.00083 micro_f1score:0.96994\n",
            "epoch:162 loss:0.07319 hamming_loss:0.00078 micro_f1score:0.97152\n",
            "epoch:163 loss:0.07039 hamming_loss:0.00075 micro_f1score:0.97278\n",
            "epoch:164 loss:0.07086 hamming_loss:0.00076 micro_f1score:0.97234\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:165 loss:0.06513 hamming_loss:0.00068 micro_f1score:0.97529\n",
            "epoch:166 loss:0.06808 hamming_loss:0.00072 micro_f1score:0.97392\n",
            "epoch:167 loss:0.06640 hamming_loss:0.00068 micro_f1score:0.97518\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:168 loss:0.06447 hamming_loss:0.00066 micro_f1score:0.97593\n",
            "epoch:169 loss:0.06703 hamming_loss:0.00072 micro_f1score:0.97385\n",
            "epoch:170 loss:0.07059 hamming_loss:0.00070 micro_f1score:0.97451\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:171 loss:0.06297 hamming_loss:0.00065 micro_f1score:0.97637\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:172 loss:0.06191 hamming_loss:0.00066 micro_f1score:0.97601\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:173 loss:0.06133 hamming_loss:0.00063 micro_f1score:0.97716\n",
            "epoch:174 loss:0.06714 hamming_loss:0.00072 micro_f1score:0.97382\n",
            "epoch:175 loss:0.06525 hamming_loss:0.00066 micro_f1score:0.97601\n",
            "epoch:176 loss:0.06454 hamming_loss:0.00068 micro_f1score:0.97519\n",
            "epoch:177 loss:0.06246 hamming_loss:0.00067 micro_f1score:0.97561\n",
            "epoch:178 loss:0.06865 hamming_loss:0.00068 micro_f1score:0.97547\n",
            "epoch:179 loss:0.06293 hamming_loss:0.00065 micro_f1score:0.97627\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:180 loss:0.06118 hamming_loss:0.00063 micro_f1score:0.97729\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:181 loss:0.06088 hamming_loss:0.00064 micro_f1score:0.97666\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:182 loss:0.06042 hamming_loss:0.00065 micro_f1score:0.97639\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:183 loss:0.06019 hamming_loss:0.00057 micro_f1score:0.97918\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:184 loss:0.05719 hamming_loss:0.00062 micro_f1score:0.97739\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:185 loss:0.05507 hamming_loss:0.00057 micro_f1score:0.97919\n",
            "epoch:186 loss:0.06034 hamming_loss:0.00064 micro_f1score:0.97673\n",
            "epoch:187 loss:0.06738 hamming_loss:0.00071 micro_f1score:0.97433\n",
            "epoch:188 loss:0.06089 hamming_loss:0.00062 micro_f1score:0.97740\n",
            "epoch:189 loss:0.05788 hamming_loss:0.00063 micro_f1score:0.97720\n",
            "epoch:190 loss:0.05789 hamming_loss:0.00057 micro_f1score:0.97926\n",
            "epoch:191 loss:0.05516 hamming_loss:0.00057 micro_f1score:0.97936\n",
            "epoch:192 loss:0.05642 hamming_loss:0.00057 micro_f1score:0.97941\n",
            "epoch:193 loss:0.06423 hamming_loss:0.00064 micro_f1score:0.97676\n",
            "epoch:194 loss:0.06821 hamming_loss:0.00066 micro_f1score:0.97593\n",
            "epoch:195 loss:0.05776 hamming_loss:0.00061 micro_f1score:0.97796\n",
            "epoch:196 loss:0.05652 hamming_loss:0.00059 micro_f1score:0.97841\n",
            "epoch:197 loss:0.05659 hamming_loss:0.00056 micro_f1score:0.97983\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:198 loss:0.05431 hamming_loss:0.00058 micro_f1score:0.97891\n",
            "epoch:199 loss:0.05906 hamming_loss:0.00060 micro_f1score:0.97807\n",
            "epoch:200 loss:0.06189 hamming_loss:0.00062 micro_f1score:0.97753\n",
            "epoch:201 loss:0.06048 hamming_loss:0.00061 micro_f1score:0.97800\n",
            "epoch:202 loss:0.06555 hamming_loss:0.00064 micro_f1score:0.97668\n",
            "epoch:203 loss:0.06187 hamming_loss:0.00058 micro_f1score:0.97890\n",
            "epoch:204 loss:0.05633 hamming_loss:0.00059 micro_f1score:0.97840\n",
            "epoch:205 loss:0.05585 hamming_loss:0.00058 micro_f1score:0.97905\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:206 loss:0.05246 hamming_loss:0.00052 micro_f1score:0.98121\n",
            "epoch:207 loss:0.06182 hamming_loss:0.00063 micro_f1score:0.97708\n",
            "epoch:208 loss:0.05718 hamming_loss:0.00059 micro_f1score:0.97842\n",
            "epoch:209 loss:0.05763 hamming_loss:0.00058 micro_f1score:0.97890\n",
            "epoch:210 loss:0.05768 hamming_loss:0.00057 micro_f1score:0.97923\n",
            "epoch:211 loss:0.05897 hamming_loss:0.00061 micro_f1score:0.97781\n",
            "epoch:212 loss:0.07826 hamming_loss:0.00072 micro_f1score:0.97393\n",
            "epoch:213 loss:0.06784 hamming_loss:0.00066 micro_f1score:0.97595\n",
            "epoch:214 loss:0.06154 hamming_loss:0.00062 micro_f1score:0.97750\n",
            "epoch:215 loss:0.05300 hamming_loss:0.00054 micro_f1score:0.98034\n",
            "epoch:216 loss:0.05476 hamming_loss:0.00056 micro_f1score:0.97953\n",
            "epoch:217 loss:0.05661 hamming_loss:0.00059 micro_f1score:0.97856\n",
            "epoch:218 loss:0.05412 hamming_loss:0.00055 micro_f1score:0.97993\n",
            "epoch:219 loss:0.05396 hamming_loss:0.00054 micro_f1score:0.98043\n",
            "epoch:220 loss:0.05268 hamming_loss:0.00057 micro_f1score:0.97944\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:221 loss:0.05240 hamming_loss:0.00055 micro_f1score:0.98014\n",
            "epoch:222 loss:0.05502 hamming_loss:0.00055 micro_f1score:0.98017\n",
            "epoch:223 loss:0.05330 hamming_loss:0.00055 micro_f1score:0.97995\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:224 loss:0.04863 hamming_loss:0.00049 micro_f1score:0.98237\n",
            "epoch:225 loss:0.05270 hamming_loss:0.00054 micro_f1score:0.98052\n",
            "epoch:226 loss:0.05507 hamming_loss:0.00056 micro_f1score:0.97955\n",
            "epoch:227 loss:0.04926 hamming_loss:0.00053 micro_f1score:0.98065\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:228 loss:0.04709 hamming_loss:0.00049 micro_f1score:0.98231\n",
            "epoch:229 loss:0.04739 hamming_loss:0.00048 micro_f1score:0.98247\n",
            "epoch:230 loss:0.04918 hamming_loss:0.00053 micro_f1score:0.98063\n",
            "epoch:231 loss:0.04903 hamming_loss:0.00051 micro_f1score:0.98159\n",
            "epoch:232 loss:0.04984 hamming_loss:0.00048 micro_f1score:0.98275\n",
            "epoch:233 loss:0.05078 hamming_loss:0.00053 micro_f1score:0.98076\n",
            "epoch:234 loss:0.05207 hamming_loss:0.00053 micro_f1score:0.98075\n",
            "epoch:235 loss:0.05309 hamming_loss:0.00053 micro_f1score:0.98093\n",
            "epoch:236 loss:0.05024 hamming_loss:0.00047 micro_f1score:0.98299\n",
            "epoch:237 loss:0.05273 hamming_loss:0.00053 micro_f1score:0.98092\n",
            "epoch:238 loss:0.04883 hamming_loss:0.00050 micro_f1score:0.98202\n",
            "epoch:239 loss:0.05456 hamming_loss:0.00056 micro_f1score:0.97977\n",
            "epoch:240 loss:0.06651 hamming_loss:0.00065 micro_f1score:0.97644\n",
            "epoch:241 loss:0.07140 hamming_loss:0.00069 micro_f1score:0.97494\n",
            "epoch:242 loss:0.05549 hamming_loss:0.00058 micro_f1score:0.97900\n",
            "epoch:243 loss:0.05137 hamming_loss:0.00054 micro_f1score:0.98048\n",
            "epoch:244 loss:0.05197 hamming_loss:0.00052 micro_f1score:0.98117\n",
            "epoch:245 loss:0.05157 hamming_loss:0.00051 micro_f1score:0.98149\n",
            "epoch:246 loss:0.04883 hamming_loss:0.00048 micro_f1score:0.98248\n",
            "Saved best model to MAGNET_best_model_final.pt\n",
            "epoch:247 loss:0.04495 hamming_loss:0.00047 micro_f1score:0.98304\n",
            "epoch:248 loss:0.04525 hamming_loss:0.00046 micro_f1score:0.98333\n",
            "epoch:249 loss:0.04911 hamming_loss:0.00049 micro_f1score:0.98214\n",
            "epoch:250 loss:0.04834 hamming_loss:0.00049 micro_f1score:0.98206\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.033 MB of 0.033 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3909f64cb512446c95ebe24cf5b3041b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇███</td></tr><tr><td>hamming_loss</td><td>█▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▅▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>micro_f1_score</td><td>▁▂▃▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>250</td></tr><tr><td>hamming_loss</td><td>0.00049</td></tr><tr><td>loss</td><td>0.04834</td></tr><tr><td>micro_f1_score</td><td>0.98206</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">resilient-firefly-13</strong> at: <a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification/runs/ze0gqgn4' target=\"_blank\">https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification/runs/ze0gqgn4</a><br/> View project at: <a href='https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification' target=\"_blank\">https://wandb.ai/quachtuananh1908-hanoi-university-of-science-and-technology/magnet-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241214_160032-ze0gqgn4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EVALUATING\n"
      ],
      "metadata": {
        "id": "w4GC5CNeQEf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, label_embedding, y_test, batch_size=250):\n",
        "    model.eval()\n",
        "    test_data = DataLoader(dataset(X_test, y_test), batch_size=batch_size)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    label_embedding = label_embedding.to(device)\n",
        "    y_pred = []\n",
        "    test_loss = 0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(X, label_embedding)\n",
        "            loss = criterion(out, y.float())\n",
        "            test_loss += loss.item()\n",
        "            y_pred.append(torch.sigmoid(out).round().cpu())\n",
        "\n",
        "    y_pred = torch.vstack(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "    hammingloss = hamming_loss(y_test, y_pred)\n",
        "\n",
        "    print(f\"Test Results:\")\n",
        "    print(f\"Loss: {test_loss:.5f}\")\n",
        "    print(f\"Micro F1: {f1_micro:.5f}\")\n",
        "    print(f\"Hamming Loss: {hammingloss:.5f}\")\n",
        "\n",
        "    return y_pred, test_loss"
      ],
      "metadata": {
        "id": "5UwdjQBlLm5W"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage:\n",
        "# First load your saved model if necessary\n",
        "# model = MAGNET(300, 250, adj_matrix, glove_embedding_matrix,heads=8)\n",
        "# modelll = load_checkpoint(model, 'MAGNET_best_model_final.pt')\n",
        "# predictions, test_loss = evaluate(modelll, X_test, glove_label_embedding, y_test)"
      ],
      "metadata": {
        "id": "pkH8y30tnqZb"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}