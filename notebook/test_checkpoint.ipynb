{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 76\u001b[0m\n\u001b[1;32m     72\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     74\u001b[0m predicted_token_class_ids \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m predicted_tokens_classes \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label[t\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m predicted_token_class_ids[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_tokens_classes)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# ['O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'I-LOC', 'O', 'I-LOC', 'I-LOC'] \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_course/lib/python3.10/site-packages/torch/_tensor.py:1109\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[1;32m   1111\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1112\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1118\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ardi555/bert_base_uncased_reuters21578_reducedto15\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ardi555/bert_base_uncased_reuters21578_reducedto15\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "text = \"\"\"\n",
    "BAHIA COCOA REVIEW\n",
    "  Showers continued throughout the week in\n",
    "  the Bahia cocoa zone, alleviating the drought since early\n",
    "  January and improving prospects for the coming temporao,\n",
    "  although normal humidity levels have not been restored,\n",
    "  Comissaria Smith said in its weekly review.\n",
    "      The dry period means the temporao will be late this year.\n",
    "      Arrivals for the week ended February 22 were 155,221 bags\n",
    "  of 60 kilos making a cumulative total for the season of 5.93\n",
    "  mln against 5.81 at the same stage last year. Again it seems\n",
    "  that cocoa delivered earlier on consignment was included in the\n",
    "  arrivals figures.\n",
    "      Comissaria Smith said there is still some doubt as to how\n",
    "  much old crop cocoa is still available as harvesting has\n",
    "  practically come to an end. With total Bahia crop estimates\n",
    "  around 6.4 mln bags and sales standing at almost 6.2 mln there\n",
    "  are a few hundred thousand bags still in the hands of farmers,\n",
    "  middlemen, exporters and processors.\n",
    "      There are doubts as to how much of this cocoa would be fit\n",
    "  for export as shippers are now experiencing dificulties in\n",
    "  obtaining +Bahia superior+ certificates.\n",
    "      In view of the lower quality over recent weeks farmers have\n",
    "  sold a good part of their cocoa held on consignment.\n",
    "      Comissaria Smith said spot bean prices rose to 340 to 350\n",
    "  cruzados per arroba of 15 kilos.\n",
    "      Bean shippers were reluctant to offer nearby shipment and\n",
    "  only limited sales were booked for March shipment at 1,750 to\n",
    "  1,780 dlrs per tonne to ports to be named.\n",
    "      New crop sales were also light and all to open ports with\n",
    "  June/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\n",
    "  under New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\n",
    "  per tonne FOB.\n",
    "      Routine sales of butter were made. March/April sold at\n",
    "  4,340, 4,345 and 4,350 dlrs.\n",
    "      April/May butter went at 2.27 times New York May, June/July\n",
    "  at 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\n",
    "  2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\n",
    "  2.27 times New York Dec, Comissaria Smith said.\n",
    "      Destinations were the U.S., Covertible currency areas,\n",
    "  Uruguay and open ports.\n",
    "      Cake sales were registered at 785 to 995 dlrs for\n",
    "  March/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\n",
    "  New York Dec for Oct/Dec.\n",
    "      Buyers were the U.S., Argentina, Uruguay and convertible\n",
    "  currency areas.\n",
    "      Liquor sales were limited with March/April selling at 2,325\n",
    "  and 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\n",
    "  York July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\n",
    "  Sept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\n",
    "  said.\n",
    "      Total Bahia sales are currently estimated at 6.13 mln bags\n",
    "  against the 1986/87 crop and 1.06 mln bags against the 1987/88\n",
    "  crop.\n",
    "      Final figures for the period to February 28 are expected to\n",
    "  be published by the Brazilian Cocoa Trade Commission after\n",
    "  carnival which ends midday on February 27.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "print(model.config.id2label[predicted_class_id])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
